{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load model and embedding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import random\n",
    "from utils import *\n",
    "from state import *\n",
    "from attention_model import AttentionModel\n",
    "\n",
    "theano.config.floatX='float32'\n",
    "\n",
    "model_name = 'model/attention_emb256_h512_v2_model.npz'\n",
    "\n",
    "state = prototype_state()\n",
    "model = AttentionModel(state, test_mode=True)\n",
    "model.load(model_name)\n",
    "\n",
    "(word2ind, ind2word) = cPickle.load(open('tmp/dict.pkl'))\n",
    "\n",
    "print('Data loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to mannually provide an input sentence (if a word is out of vocab, we simply remove it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.25117277e-02   1.52548282e-07   8.61931010e-04 ...,   9.30724607e-04\n",
      "    9.86388768e-04   9.74392053e-04]\n",
      " [  9.99993682e-01   0.00000000e+00   1.22841430e-15 ...,   1.59289734e-15\n",
      "    3.36927048e-15   2.03691921e-15]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    8.40779079e-45   1.40129846e-45]\n",
      " ..., \n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3e165954536a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "test_sents = ['moderately priced swedish food', 'how about asian oriental', 'chinese food', \\\n",
    "              'moderately australian food', 'is there any serving vietnamese']\n",
    "\n",
    "for (k, test_sent) in enumerate(test_sents):\n",
    "    words = test_sent.split()\n",
    "    nat_coded = [1]\n",
    "    for w in words:\n",
    "        if w in word2ind:\n",
    "            nat_coded.append(word2ind[w])\n",
    "        else:\n",
    "            print '  out of vocab: %s' % w\n",
    "    nat_coded.append(0)\n",
    "    #print 'Coded input:', nat_coded\n",
    "\n",
    "    m = state['seq_len_in']\n",
    "    nat_coded_mat = numpy.zeros((m, 2), dtype='int32')\n",
    "    nat_mask = numpy.zeros((m, 2), dtype='float32')\n",
    "    sent_len = len(nat_coded)\n",
    "    nat_coded_mat[:sent_len, 0] = nat_coded\n",
    "    nat_mask[:sent_len, 0] = 1\n",
    "    pred_fn = theano.function([model.x_data, model.xmask],\n",
    "                                    model.ot)\n",
    "    pred = pred_fn(nat_coded_mat, nat_mask)\n",
    "    #print 'NAT_coded:', nat_coded_mat\n",
    "    #print 'NAT_mask:', nat_mask\n",
    "    #print 'Prediction (coded):', pred\n",
    "\n",
    "    res_col = pred[:, 0]\n",
    "    print res_col\n",
    "    \n",
    "    for col in res_col:\n",
    "        print col.argmax()\n",
    "\n",
    "    res = []\n",
    "    for ind in res_col:\n",
    "        res.append(ind)\n",
    "        if ind == 0:\n",
    "            break\n",
    "\n",
    "    print \"%d: %s\\n %s\" % (k, test_sent, ' '.join([ind2word[ind] for ind in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
