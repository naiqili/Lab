{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load model and embedding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import random\n",
    "from utils import *\n",
    "from state import *\n",
    "from title_model import TitleModel\n",
    "\n",
    "theano.config.floatX='float64'\n",
    "\n",
    "model_name = 'model/title_emb256_h256_rmsprop_f64_model.npz'\n",
    "\n",
    "state = title_state()\n",
    "model = TitleModel(state, test_mode=True)\n",
    "model.load(model_name)\n",
    "\n",
    "(ind2word, word2ind, _, _, _) = cPickle.load(open('data/dict.pkl'))\n",
    "\n",
    "print('Data loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to mannually provide an input sentence (if a word is out of vocab, we simply remove it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sent: i would like to go hiking tomorrow\n",
      "  out of vocab: hiking\n",
      "  out of vocab: tomorrow\n",
      "Coded input: [1, 1014, 109, 1051, 41, 603, 17, 18, 0]\n",
      "<START> i would like to go <TOK15> <TOK16> <END>\n",
      "Explanation of: <NO>\n",
      "    <END>: 0.2341\n",
      "    i: 0.1823\n",
      "    <TOK16>: 0.1695\n",
      "    <START>: 0.1472\n",
      "    would: 0.1222\n",
      "    <TOK15>: 0.0513\n",
      "    like: 0.0448\n",
      "    to: 0.0249\n",
      "    go: 0.0236\n",
      "\n",
      "<START> <NO> <END>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def restoreW(ind_lst, ind2word):\n",
    "    res = []\n",
    "    for ind in ind_lst:\n",
    "        if ind in ind2word:\n",
    "            res.append(ind2word[ind])\n",
    "    return ' '.join(res)\n",
    "    \n",
    "\n",
    "test_sents = ['i would like to go hiking tomorrow']\n",
    "\n",
    "for (k, test_sent) in enumerate(test_sents):\n",
    "    print \"Test sent:\", test_sent\n",
    "    words = test_sent.split()\n",
    "    nat_coded = [1]\n",
    "    tok_set = range(20)\n",
    "    for w in words:\n",
    "        if w in word2ind:\n",
    "            nat_coded.append(word2ind[w])\n",
    "        else:\n",
    "            if w in tmp_map:\n",
    "                nat_coded.append(tmp_map[w])\n",
    "            else:\n",
    "                tok_ind = random.choice(tok_set)\n",
    "                tok_s = '<TOK%d>' % tok_ind\n",
    "                tok_set.remove(tok_ind)\n",
    "                nat_coded.append(word2ind[tok_s])\n",
    "            print '  out of vocab: %s' % w\n",
    "    nat_coded.append(0)\n",
    "    print 'Coded input:', nat_coded\n",
    "    print restoreW(nat_coded, ind2word)\n",
    "\n",
    "    m = state['seq_len_in']\n",
    "    nat_coded_mat = numpy.zeros((m, 2), dtype='int32')\n",
    "    nat_mask = numpy.zeros((m, 2), dtype='float64')\n",
    "    sent_len = len(nat_coded)\n",
    "    nat_coded_mat[:sent_len, 0] = nat_coded\n",
    "    nat_mask[:sent_len, 0] = 1\n",
    "    nat_coded_mat[:sent_len, 1] = nat_coded\n",
    "    nat_mask[:sent_len, 1] = 1\n",
    "    pred_fn = model.build_gen_function()\n",
    "    \n",
    "    res = [1]\n",
    "    abs_in = 1\n",
    "    model.gen_reset()\n",
    "    while True:\n",
    "        abs_in_mat = np.zeros((2, ), dtype='int32') + abs_in\n",
    "        #print 'abs_in', abs_in_mat\n",
    "        [p_t, o_t, alpha_t] = pred_fn(nat_coded_mat, nat_mask, abs_in_mat)\n",
    "        #print \"ot\", o_t, ind2word[o_t[0]]\n",
    "        pt_col = p_t[0]\n",
    "        alpha_t = alpha_t[:, 0]\n",
    "        #print alpha_t\n",
    "        alpha_s = alpha_t.argsort()[::-1]\n",
    "        #print sum(pt_col)\n",
    "        pt_norm = [1.0 * a / sum(pt_col) for a in pt_col]\n",
    "        #print pt_norm\n",
    "        ind = np.asarray(pt_norm).argmax()\n",
    "        abs_in = ind\n",
    "        res.append(ind)\n",
    "        if ind == 0 or len(res) > 10:        \n",
    "            break\n",
    "        \n",
    "        print 'Explanation of: %s' % restoreW([ind], ind2word)\n",
    "        for k in alpha_s[:len(nat_coded)]:\n",
    "            print \"    %s: %.4f\" % (restoreW([nat_coded[k]], ind2word), alpha_t[k])\n",
    "    print\n",
    "    print restoreW(res, ind2word)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
