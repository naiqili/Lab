{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import build_graph\n",
    "import cPickle\n",
    "from reader import get_raw_data\n",
    "import random\n",
    "from reader import _word2ind\n",
    "\n",
    "flags = tf.flags\n",
    "flags.DEFINE_integer(\"vocab_size\", 50000, \"Vocab size\")\n",
    "flags.DEFINE_integer(\"emb_size\", 300, \"Embedding size\")\n",
    "flags.DEFINE_integer(\"cell_size\", 100, \"Cell size\")\n",
    "flags.DEFINE_integer(\"N\", 5, \"Number of test cases\")\n",
    "flags.DEFINE_string(\"cell_type\", 'GRU', \"Cell type\")\n",
    "flags.DEFINE_string(\"rnn_type\", 'bi_dynamic', \"Cell type\")\n",
    "flags.DEFINE_string(\"datafile\", './_data/7000/nlu_data.pkl', \"Data file (.pkl)\")\n",
    "flags.DEFINE_string(\"dictfile\", './tmp/dict.pkl', \"Dict file (.pkl)\")\n",
    "flags.DEFINE_string(\"modelfile\", 'None', \"model file\")\n",
    "flags.DEFINE_string(\"target\", 'title', \"What to test (title/location/data/whenst/whened/invitee)\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "all_data = cPickle.load(open(FLAGS.datafile))\n",
    "(word2ind, ind2word) = cPickle.load(open(FLAGS.dictfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Model\"):\n",
    "    tf_x = tf.placeholder(tf.int32, shape=(1, 60), name='x')\n",
    "    tf_y = tf.placeholder(tf.int32, shape=(1, 60), name='y')\n",
    "    tf_len = tf.placeholder(tf.int32, shape=(1), name='len')\n",
    "    tf_mask = tf.to_float(tf.not_equal(tf_x, 0))\n",
    "    g_title = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=FLAGS.vocab_size, \\\n",
    "                        emb_size=FLAGS.emb_size, \\\n",
    "                        cell_size=FLAGS.cell_size, \\\n",
    "                        cell_type=FLAGS.cell_type, \\\n",
    "                        rnn_type=FLAGS.rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "    g_location = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=FLAGS.vocab_size, \\\n",
    "                        emb_size=FLAGS.emb_size, \\\n",
    "                        cell_size=FLAGS.cell_size, \\\n",
    "                        cell_type=FLAGS.cell_type, \\\n",
    "                        rnn_type=FLAGS.rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "    g_invitee = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=FLAGS.vocab_size, \\\n",
    "                        emb_size=FLAGS.emb_size, \\\n",
    "                        cell_size=FLAGS.cell_size, \\\n",
    "                        cell_type=FLAGS.cell_type, \\\n",
    "                        rnn_type=FLAGS.rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "    g_day = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=FLAGS.vocab_size, \\\n",
    "                        emb_size=FLAGS.emb_size, \\\n",
    "                        cell_size=FLAGS.cell_size, \\\n",
    "                        cell_type=FLAGS.cell_type, \\\n",
    "                        rnn_type=FLAGS.rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "    g_whenst = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=FLAGS.vocab_size, \\\n",
    "                        emb_size=FLAGS.emb_size, \\\n",
    "                        cell_size=FLAGS.cell_size, \\\n",
    "                        cell_type=FLAGS.cell_type, \\\n",
    "                        rnn_type=FLAGS.rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "    g_whened = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=FLAGS.vocab_size, \\\n",
    "                        emb_size=FLAGS.emb_size, \\\n",
    "                        cell_size=FLAGS.cell_size, \\\n",
    "                        cell_type=FLAGS.cell_type, \\\n",
    "                        rnn_type=FLAGS.rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sents = [\"i would like to go to the library at three p.m. tomorrow afternoon\",\n",
    "              \"go swimming with alice and bob tomorrow\"]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    g_title['saver'].restore(sess, title_modelfile)\n",
    "    g_location['saver'].restore(sess, location_modelfile)\n",
    "    g_invitee['saver'].restore(sess, invitee_modelfile)\n",
    "    g_day['saver'].restore(sess, day_modelfile)\n",
    "    g_whenst['saver'].restore(sess, whenst_modelfile)\n",
    "    g_whened['saver'].restore(sess, whened_modelfile)\n",
    "    for _n, sent in enumerate(test_sents):\n",
    "        print \n",
    "        print \"test case:\", _n\n",
    "        print sent\n",
    "        \n",
    "        def process(g, text):\n",
    "            tok_text = nltk.word_tokenize(text)\n",
    "            _len = len(tok_text)\n",
    "\n",
    "            x_mat = np.zeros((1, 60), dtype=np.int32)\n",
    "            y_mat = np.zeros((1, 60), dtype=np.int32)\n",
    "            len_mat = np.zeros((1,), dtype=np.int32)\n",
    "\n",
    "            for i, w in enumerate(tok_text):\n",
    "                x_mat[0][i] = _word2ind(w, word2ind)\n",
    "            y_mat[0][:_len] = tok_y[:]\n",
    "            len_mat[0] = _len\n",
    "\n",
    "            preds = sess.run([g['preds']], feed_dict={tf_x: x_mat, tf_len: len_mat})\n",
    "            #print \"sent:\", ' '.join(tok_text)\n",
    "            #print \"prediction:\", preds\n",
    "            pred_text = []\n",
    "            for i, b in enumerate(preds):\n",
    "                if i == len(tok_text):\n",
    "                    break\n",
    "                if b == 1:\n",
    "                    pred_text.append(tok_text[i])\n",
    "            return ' '.join(pred_text)\n",
    "        \n",
    "        pred_title = process(g_title, sent)\n",
    "        pred_location = process(g_location, sent)\n",
    "        pred_invitee = process(g_invitee, sent)\n",
    "        pred_day = process(g_day, sent)\n",
    "        pred_whenst = process(g_whenst, sent)\n",
    "        pred_whened = process(g_whened, sent)\n",
    "        \n",
    "        print \"title:\", pred_title\n",
    "        print \"location:\", pred_location\n",
    "        print \"invitee:\", pred_invitee\n",
    "        print \"day:\", pred_day\n",
    "        print \"whenst:\", pred_whenst\n",
    "        print \"whened:\", pred_whened"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
