{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import build_graph\n",
    "import cPickle\n",
    "from reader import get_raw_data\n",
    "import random\n",
    "from reader import _word2ind\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "vocab_size = 50000\n",
    "emb_size = 300\n",
    "cell_size = 100\n",
    "N =5\n",
    "cell_type = 'GRU'\n",
    "rnn_type = 'bi_dynamic'\n",
    "datafile = './_data/7000/nlu_data.pkl'\n",
    "dictfile = './tmp/dict.pkl'\n",
    "title_modelfile = './model/title/best'\n",
    "location_modelfile = './model/location/best'\n",
    "invitee_modelfile = './model/invitee/best'\n",
    "day_modelfile = './model/day/best'\n",
    "whenst_modelfile = './model/whenst/best'\n",
    "whened_modelfile = './model/whened/best'\n",
    "\n",
    "all_data = cPickle.load(open(datafile))\n",
    "(word2ind, ind2word) = cPickle.load(open(dictfile))\n",
    "\n",
    "print \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...OK\n"
     ]
    }
   ],
   "source": [
    "tf_x = tf.placeholder(tf.int32, shape=(1, 60), name='x')\n",
    "tf_y = tf.placeholder(tf.int32, shape=(1, 60), name='y')\n",
    "tf_len = tf.placeholder(tf.int32, shape=(1), name='len')\n",
    "tf_mask = tf.to_float(tf.not_equal(tf_x, 0))\n",
    "with tf.variable_scope(\"Model_title\") as scope:    \n",
    "    g_title = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=vocab_size, \\\n",
    "                        emb_size=emb_size, \\\n",
    "                        cell_size=cell_size, \\\n",
    "                        cell_type=cell_type, \\\n",
    "                        rnn_type=rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                    is_training=False)\n",
    "with tf.variable_scope(\"Model_location\") as scope:    \n",
    "    g_location = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=vocab_size, \\\n",
    "                        emb_size=emb_size, \\\n",
    "                        cell_size=cell_size, \\\n",
    "                        cell_type=cell_type, \\\n",
    "                        rnn_type=rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "with tf.variable_scope(\"Model_invitee\"):    \n",
    "    g_invitee = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=vocab_size, \\\n",
    "                        emb_size=emb_size, \\\n",
    "                        cell_size=cell_size, \\\n",
    "                        cell_type=cell_type, \\\n",
    "                        rnn_type=rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "with tf.variable_scope(\"Model_day\"):    \n",
    "    g_day = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=vocab_size, \\\n",
    "                        emb_size=emb_size, \\\n",
    "                        cell_size=cell_size, \\\n",
    "                        cell_type=cell_type, \\\n",
    "                        rnn_type=rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "with tf.variable_scope(\"Model_whenst\"):    \n",
    "    g_whenst = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=vocab_size, \\\n",
    "                        emb_size=emb_size, \\\n",
    "                        cell_size=cell_size, \\\n",
    "                        cell_type=cell_type, \\\n",
    "                        rnn_type=rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "with tf.variable_scope(\"Model_whened\"):    \n",
    "    g_whened = build_graph(tf_x, tf_y, tf_len, tf_mask, \\\n",
    "                        vocab_size=vocab_size, \\\n",
    "                        emb_size=emb_size, \\\n",
    "                        cell_size=cell_size, \\\n",
    "                        cell_type=cell_type, \\\n",
    "                        rnn_type=rnn_type, \\\n",
    "                        batch_size=1, \\\n",
    "                        is_training=False)\n",
    "print \"...OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test case: 0\n",
      "i would like to go to the library at three p.m. tomorrow afternoon\n",
      "title: go to the library\n",
      "location: \n",
      "invitee: \n",
      "day: \n",
      "whenst: three p.m.\n",
      "whened: \n",
      "\n",
      "test case: 1\n",
      "go swimming with alice and bob tomorrow\n",
      "title: go swimming\n",
      "location: \n",
      "invitee: alice bob\n",
      "day: \n",
      "whenst: \n",
      "whened: \n",
      "\n",
      "test case: 2\n",
      "i plan to sleep all day this sunday at home\n",
      "title: sleep\n",
      "location: \n",
      "invitee: \n",
      "day: this sunday\n",
      "whenst: \n",
      "whened: \n",
      "\n",
      "test case: 3\n",
      "i want to play ps4 with zhou jielun at six p.m.\n",
      "title: play ps4\n",
      "location: \n",
      "invitee: zhou jielun\n",
      "day: \n",
      "whenst: six p.m\n",
      "whened: \n",
      "\n",
      "test case: 4\n",
      "set a reminder for me tomorrow afternoon. i wish to go hiking\n",
      "title: hiking\n",
      "location: \n",
      "invitee: \n",
      "day: \n",
      "whenst: \n",
      "whened: \n",
      "\n",
      "test case: 5\n",
      "i wish to mark assignments tomorrow afternoon.\n",
      "title: assignments\n",
      "location: \n",
      "invitee: \n",
      "day: \n",
      "whenst: \n",
      "whened: \n"
     ]
    }
   ],
   "source": [
    "test_sents = [\"i would like to go to the library at three p.m. tomorrow afternoon\",\n",
    "              \"go swimming with alice and bob tomorrow\",\n",
    "              \"i plan to sleep all day this sunday at home\",\n",
    "              \"i want to play ps4 with zhou jielun at six p.m.\",\n",
    "              \"set a reminder for me tomorrow afternoon. i wish to go hiking\",\n",
    "              \"i wish to mark assignments tomorrow afternoon.\"]\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Model_title')).restore(sess, title_modelfile)\n",
    "tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Model_location')).restore(sess, location_modelfile)\n",
    "tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Model_invitee')).restore(sess, invitee_modelfile)\n",
    "tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Model_day')).restore(sess, day_modelfile)\n",
    "tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Model_whenst')).restore(sess, whenst_modelfile)\n",
    "tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Model_whened')).restore(sess, whened_modelfile)\n",
    "\n",
    "for _n, sent in enumerate(test_sents):\n",
    "    print \n",
    "    print \"test case:\", _n\n",
    "    print sent\n",
    "\n",
    "    def process(g, text):\n",
    "        tok_text = nltk.word_tokenize(text)\n",
    "        _len = len(tok_text)\n",
    "\n",
    "        x_mat = np.zeros((1, 60), dtype=np.int32)\n",
    "        len_mat = np.zeros((1,), dtype=np.int32)\n",
    "\n",
    "        for i, w in enumerate(tok_text):\n",
    "            x_mat[0][i] = _word2ind(w, word2ind)\n",
    "        len_mat[0] = _len\n",
    "\n",
    "        preds = sess.run([g['preds']], feed_dict={tf_x: x_mat, tf_len: len_mat})\n",
    "        #print \"sent:\", ' '.join(tok_text)\n",
    "        #print \"prediction:\", preds\n",
    "        pred_text = []\n",
    "        for i, b in enumerate(preds[0]):\n",
    "            if i == len(tok_text):\n",
    "                break\n",
    "            if b == 1:\n",
    "                pred_text.append(tok_text[i])\n",
    "        return ' '.join(pred_text)\n",
    "\n",
    "    pred_title = process(g_title, sent)\n",
    "    pred_location = process(g_location, sent)\n",
    "    pred_invitee = process(g_invitee, sent)\n",
    "    pred_day = process(g_day, sent)\n",
    "    pred_whenst = process(g_whenst, sent)\n",
    "    pred_whened = process(g_whened, sent)\n",
    "    \n",
    "    print \"title:\", pred_title\n",
    "    print \"location:\", pred_location\n",
    "    print \"invitee:\", pred_invitee\n",
    "    print \"day:\", pred_day\n",
    "    print \"whenst:\", pred_whenst\n",
    "    print \"whened:\", pred_whened\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
