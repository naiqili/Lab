{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental results and comparisons\n",
    "\n",
    "## Reported state-of-the-art results\n",
    "\n",
    "<img src=\"./_doc/reported_exp.png\" alt=\"table\" style=\"width: 450px;\"/>\n",
    "\n",
    "The table above is from the paper *Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks*.\n",
    "\n",
    "The best reported results known to me are (**Fine-grained: 52.1, Binary: 88.6**), as shown in *Ask Me Anything : Dynamic Memory Networks for Natural Language Processing*.\n",
    "\n",
    "## Results in my experiments\n",
    "\n",
    "Algorithm | Cell Size | Attn Size | Network Size | Fine-grained Acc. | Binary Acc.\n",
    "--------- | --------- | --------- | ------------ | ----------------- | -----------\n",
    "[LSTM baseline](#LSTM-Baseline) | 300 | - | 1,351,550 | 49.8 | 89.0\n",
    "[LSTM + ATTN 1](#LSTM-+-ATTN) | 150 | 100 | 480,850 | 50.9 | 89.2\n",
    "[LSTM + ATTN 2](#LSTM-+-ATTN-2) | 200 | 100 | 741,100 | 51.3 | 89.0\n",
    "[LSTM + ATTN 3](#LSTM-+-ATTN-3) | 300 | 100 | 1,411,600 | 51.1 | 88.1\n",
    "LSTM + ATTN + Layer2 | 200 | 100 | 1,542,200 | 49.2 | 89.1\n",
    "LSTM + ATTN + Layer2 | 300 | 100 | 3,183,200 | 51.5 | 89.4\n",
    "[RNN + ATTN](#RNN-+-ATTN) | 400 | 100 | 800,500 | 45.3 | 84.9\n",
    "[RNN + ATTN + 2Layers](#RNN-+-ATTN-+-2Layers) | 400 | 150 | 1,801,100 | 47.1 | 86.7\n",
    "GRU v1 + ATTN | 150 | 100 | 480,850 | 51.1 | 87.4\n",
    "GRU v1 + ATTN | 400 | 100 | 2,282,100 | 51.9 | 89.4\n",
    "GRU v1 + ATTN + Layer2 | 200 | 100 | 1,400,200 | 47.5 | 88.2\n",
    "GRU v1 + ATTN + Layer2 | 300 | 100 | 2,823,200 | 48.6 | 86.5\n",
    "GRU v1 + ATTN + Layer2 | 400 | 100 | 4,764,200 | 48.7 | 86.5\n",
    "GRU v2 + ATTN | 400 | 100 | 1,841,700 | 50.1 | 88.5\n",
    "\n",
    "## Summary\n",
    "\n",
    "- The combination of Recursive LSTM and attention (LSTM+ATTN) mechanism has resulted in new state-of-the-art result on the binary Stanford Sentiment Treebank (accuracy improved from 88.6% to 89.2%.\n",
    "- LSTM+ATTN not only has higher accuracy, but also achieve the accuracy with much fewer parameters.\n",
    "- After using the attention mechanism, the basic recursive neural network is also improved to be a competitve algorithm.\n",
    "- The attention mechanism provides interpretable results: we can know why a sentence is classified as positive or negative, by inspecting the most important substrings. For example in the example [here](#A-positive-example), the sentence \"The movie 's ripe, enrapturing beauty will tempt those willing to probe its inscrutable mysteries.\" is classified as positive because:\n",
    "    - It detects some positive words: willing, beauty.\n",
    "    - It also detects a complex positive phrase: will tempt those willing to probe its inscrutable mysteries.\n",
    "- The attention mechanism is not a new idea, but the combination with recusive neural network has the following extra advantages:\n",
    "    - Now we can pay attention to phrases with arbitrary lengths, instead of some independent words.\n",
    "    - Since the phrase is from part of a parsed tree, so it is generally well structured, and generally more easily to be interpreted and understood.\n",
    "    - Experiments shows that the attention mechanism indeed captures the intuitively important words or phrases.\n",
    "\n",
    "## Experimental details\n",
    "\n",
    "The following sections (after Preliminaries) introduce the experimental details in the following aspects:\n",
    "\n",
    "- Show the confusion matrix, accuracy and some other metrics of each algorithm.\n",
    "- Show some sentences that are correctly classified.\n",
    "- Show some examples of how the attention mechanism works on the correct examples.\n",
    "- Show some sentences that are incorrectly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "import cPickle\n",
    "import os, shutil, random\n",
    "from os import path\n",
    "\n",
    "from tfrecord_reader import get_data\n",
    "\n",
    "from lstm_model import LSTMModel\n",
    "from lstm_attn_model import LSTMAttnModel\n",
    "from lstm_attn2_model import LSTMAttn2Model\n",
    "from rnn_attn_model import RNNAttnModel\n",
    "from rnn_attn2_model import RNNAttn2Model\n",
    "from gru_attn_model import GRUAttnModel\n",
    "from gru_attn2_model import GRUAttn2Model\n",
    "from gru2_attn_model import GRU2AttnModel\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20725\n",
      "examples of dict:\n",
      "\n",
      "couples 17732\n",
      "parent-child 13934\n",
      "capably 12814\n",
      "witnessed 7821\n",
      "behaving 8867\n"
     ]
    }
   ],
   "source": [
    "dict_path = \"_data/dict.pkl\"\n",
    "\n",
    "(wv_word2ind, wv_ind2word) = cPickle.load(open(dict_path))\n",
    "print len(wv_word2ind)\n",
    "wv_ind2word[len(wv_ind2word)+1] = 'OOV'\n",
    "wv_ind2word[-1] = '-1'\n",
    "\n",
    "print 'examples of dict:\\n'\n",
    "for _ in range(5):\n",
    "    (k, v) = random.choice(wv_word2ind.items())\n",
    "    print k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ind2str(ind, wv_ind2word=wv_ind2word):\n",
    "    return ' '.join([wv_ind2word[i] for i in ind])\n",
    "\n",
    "def nodeid2str(id, wv, left, right, is_leaf, wv_ind2word=wv_ind2word):\n",
    "    s = ''\n",
    "    if is_leaf[id] == 0:\n",
    "        s1 = nodeid2str(left[id], wv, left, right, is_leaf)\n",
    "        s2 = nodeid2str(right[id], wv, left, right, is_leaf)\n",
    "        s = s1 + ' ' + s2 + ' '\n",
    "    if not wv[id] == -1:\n",
    "        s = s + wv_ind2word[wv[id]]\n",
    "    return s.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples of test data\n",
      "\n",
      "Effective but -1 OOV biopic -1 -1\n",
      "[3 2 3 1 2 1 2]\n",
      "Effective but \n",
      "\n",
      "If you sometimes like to go to the movies -1 -1 -1 to have fun -1 -1 -1 -1 -1 -1 -1 -1 , Wasabi is a good place to start -1 -1 -1 -1 -1 . -1 -1 -1 -1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 3 2 2 4 3 3 3 3 2 3 3 3 2 2 2 2 3 2 2 2 2 2 2 2 3 2\n",
      " 3 2 2 3]\n",
      "sometimes\n",
      "\n",
      "Emerges as something rare -1 -1 -1 , -1 an issue movie -1 -1 that 's so honest -1 and -1 keenly observed -1 -1 -1 that it does n't -1 feel like one -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1\n",
      "[2 2 2 3 3 3 3 2 4 2 2 2 2 2 2 2 2 4 3 2 3 2 2 3 4 3 2 2 2 2 1 2 2 2 2 2 2\n",
      " 2 2 3 3 4 4 2 4]\n",
      "something\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_record = \"_data/finegrained_test.record\"\n",
    "test_size = 2210\n",
    "\n",
    "test_data = []\n",
    "\n",
    "l, wv, left, right, label, is_leaf, mask = get_data(test_record)\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "# Get all test data for demonstration\n",
    "\n",
    "for _step in range(test_size):\n",
    "    #print _step\n",
    "    _l, _wv, _left, _right, _label, _is_leaf = sess.run([l, wv, left, right, label, is_leaf])\n",
    "    test_data.append((_wv, _label, _left, _right, _is_leaf))\n",
    "    \n",
    "print 'examples of test data\\n'\n",
    "for i in range(3):\n",
    "    print ind2str(test_data[i][0])\n",
    "    print test_data[i][1]\n",
    "    print nodeid2str(2, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, layers=1):\n",
    "    print(\"Start testing\")\n",
    "    test_losses = []\n",
    "    overall_metrics = np.zeros((5, 5), dtype=np.int32)\n",
    "    root_metrics = np.zeros((5, 5), dtype=np.int32)\n",
    "    overall_binary_metrics = np.zeros((2, 2), dtype=np.int32)\n",
    "    root_binary_metrics = np.zeros((2, 2), dtype=np.int32)\n",
    "    \n",
    "    right_ind = []\n",
    "    wrong_ind = []\n",
    "    if layers == 0: # 0 means there's no attention\n",
    "        pass\n",
    "    elif layers == 1:\n",
    "        attn = []\n",
    "    else:\n",
    "        attn1 = []\n",
    "        attn2 = []\n",
    "\n",
    "    for i in xrange(test_size):\n",
    "        if layers == 0:\n",
    "            test_loss, test_pred, test_binary_pred, target_v = \\\n",
    "                sess.run([model.sum_loss, model.pred, model.binary_pred, model.ground_truth])\n",
    "        elif layers == 1:\n",
    "            test_loss, test_pred, test_binary_pred, target_v, attn_vecs = \\\n",
    "                sess.run([model.sum_loss, model.pred, model.binary_pred, model.ground_truth, model.attn_vecs])\n",
    "            attn.append(attn_vecs)\n",
    "        else:\n",
    "            test_loss, test_pred, test_binary_pred, target_v, attn_vecs1, attn_vecs2 = \\\n",
    "                sess.run([model.sum_loss, model.pred, model.binary_pred, model.ground_truth, model.attn_vecs1, model.attn_vecs2])\n",
    "            attn1.append(attn_vecs1)            \n",
    "            attn2.append(attn_vecs2)            \n",
    "        test_losses.append(test_loss)\n",
    "        root_pred = test_pred[-1]\n",
    "        root_target = target_v[-1]\n",
    "        if target_v[-1] != 2:\n",
    "            root_binary_target = (target_v[-1] > 2).astype(np.int32)\n",
    "            root_binary_pred = test_binary_pred[-1]\n",
    "            root_binary_metrics[root_binary_pred, root_binary_target] += 1\n",
    "            if root_binary_pred == root_binary_target:\n",
    "                right_ind.append(i)\n",
    "            else:\n",
    "                wrong_ind.append(i)\n",
    "        root_metrics[root_pred, root_target] += 1\n",
    "        for k in range(len(test_pred)):\n",
    "            overall_metrics[test_pred[k], target_v[k]] += 1\n",
    "            target_temp = (target_v[k] > 2).astype(np.int32)\n",
    "            if not target_v[k] == 2:\n",
    "                overall_binary_metrics[test_binary_pred[k], target_temp] += 1\n",
    "        #logger.debug(\"Validation loss %f\" % valid_loss)\n",
    "\n",
    "    sum_loss = sum(test_losses)\n",
    "    mean_loss = sum_loss / test_size\n",
    "    print('test finish')\n",
    "\n",
    "    print('Root Metrics:\\n %s' % str(root_metrics))\n",
    "    print('Overall Metrics:\\n %s' % str(overall_metrics))\n",
    "    print('Root Binary Metrics:\\n %s' % str(root_binary_metrics))\n",
    "    print('Overall Binary Metrics:\\n %s' % str(overall_binary_metrics))\n",
    "    root_acc = 1.0 * np.trace(root_metrics) / np.sum(root_metrics)\n",
    "    overall_acc = 1.0 * np.trace(overall_metrics) / np.sum(overall_metrics)\n",
    "    root_binary_acc = 1.0 * np.trace(root_binary_metrics) / np.sum(root_binary_metrics)\n",
    "    overall_binary_acc = 1.0 * np.trace(overall_binary_metrics) / np.sum(overall_binary_metrics)\n",
    "    print('mean loss: %f, root_acc: %f, overall_acc: %f, root_binary_acc: %f, overall_binary_acc: %f' % \n",
    "          (mean_loss, root_acc, overall_acc, root_binary_acc, overall_binary_acc))\n",
    "    \n",
    "    if layers == 0:\n",
    "        return right_ind, wrong_ind\n",
    "    elif layers == 1:\n",
    "        return right_ind, wrong_ind, attn\n",
    "    else:\n",
    "        return right_ind, wrong_ind, attn1, attn2        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Baseline\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 300\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 5 x CELL = 1,351,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[ 96  69   9   1   0]\n",
      " [157 408 162  54  10]\n",
      " [ 17 109 113  80  15]\n",
      " [  9  41  98 311 202]\n",
      " [  0   6   7  64 172]]\n",
      "Overall Metrics:\n",
      " [[  735   430    58     3     1]\n",
      " [ 1070  6256  2376   374    49]\n",
      " [  172  2283 52103  2662   221]\n",
      " [   29   277  1971  7482  1713]\n",
      " [    2     9    40   477  1807]]\n",
      "Root Binary Metrics:\n",
      " [[817 106]\n",
      " [ 95 803]]\n",
      "Overall Binary Metrics:\n",
      " [[10241  1023]\n",
      " [ 1022 13766]]\n",
      "mean loss: 15.936891, root_acc: 0.497738, overall_acc: 0.827881, root_binary_acc: 0.889621, overall_binary_acc: 0.921503\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/lstm_joint/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 300,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0,\n",
    "               'drop_fw_hs': False,\n",
    "               'drop_fw_cs': False\n",
    "               }\n",
    "\n",
    "test_md = LSTMModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind = test(test_md, layers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some correct binary predictions:\n",
      "\n",
      "A movie that tries to fuse the two -1 ` woods ' -1 -1 -1 -1 -1 -1 but -1 winds up -1 a OOV masala mess -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 1\n",
      "\n",
      "Collateral Damage -1 is , -1 despite its alleged provocation -1 -1 -1 -1 post-9 / 11 , -1 an antique -1 -1 , -1 in the end -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 1\n",
      "\n",
      "Chicago is sophisticated , brash , sardonic , completely joyful -1 -1 -1 -1 -1 -1 -1 -1 in its execution -1 -1 -1 . -1 -1 \tground truth label: 4\n",
      "\n",
      "Arguably the year -1 's silliest and -1 most incoherent -1 -1 movie -1 -1 . -1 -1 -1 \tground truth label: 1\n",
      "\n",
      "The drama -1 is played out -1 with such aching beauty -1 -1 and -1 truth -1 -1 -1 that it brings tears -1 to your eyes -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some correct predictions\n",
    "\n",
    "print 'Some correct binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(right_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some incorrect binary predictions:\n",
      "\n",
      "Not a bad journey -1 -1 at all -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "The best way -1 -1 to hope for any chance -1 of enjoying this film -1 -1 -1 -1 -1 -1 -1 -1 is by lowering your expectations -1 -1 -1 -1 . -1 -1 \tground truth label: 1\n",
      "\n",
      "While Benigni -LRB- who stars and -1 co-wrote -1 -1 -RRB- -1 -1 -1 seems to be having a wonderful time -1 -1 -1 -1 -1 -1 -1 -1 , he might be alone -1 in that -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 1\n",
      "\n",
      "For all its failed connections -1 -1 -1 -1 , Divine Secrets -1 of the Ya-Ya Sisterhood -1 -1 -1 -1 is nurturing -1 , -1 in a gauzy -1 , -1 dithering way -1 -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "The Transporter -1 is as lively -1 and -1 as fun -1 -1 -1 as it is unapologetically dumb -1 -1 -1 -1 -1 -1 \tground truth label: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some incorrect predictions\n",
    "\n",
    "print 'Some incorrect binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(wrong_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + ATTN \n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 150, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 5 x CELL + 2 X ATTN x CELL + ATTN = 480,850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[106  76  16   5   3]\n",
      " [155 445 176  58  11]\n",
      " [  7  54  82  55   7]\n",
      " [  9  57 108 337 223]\n",
      " [  2   1   7  55 155]]\n",
      "Overall Metrics:\n",
      " [[  924   877   254    37    10]\n",
      " [  936  6571  3826   539    66]\n",
      " [   84  1314 48576  1760    82]\n",
      " [   60   479  3843  8078  1803]\n",
      " [    4    14    49   584  1830]]\n",
      "Root Binary Metrics:\n",
      " [[822 107]\n",
      " [ 90 802]]\n",
      "Overall Binary Metrics:\n",
      " [[10282  1214]\n",
      " [  981 13575]]\n",
      "mean loss: 17.837229, root_acc: 0.509050, overall_acc: 0.798777, root_binary_acc: 0.891818, overall_binary_acc: 0.915745\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/lstm_attn_cell150_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 150,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = LSTMAttnModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn = test(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some correct binary predictions:\n",
      "\n",
      "It wo n't -1 be long -1 before you 'll spy I Spy at a video store -1 -1 near you -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 1\n",
      "\n",
      "An incredibly clever -1 and -1 superbly paced -1 -1 caper -1 -1 filled with scams -1 -1 within scams -1 -1 within scams -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "OOV handily directs and -1 edits around his screenplay 's -1 -1 sappier elements -1 -1 -1 -1 -1 ... -1 and -1 sustains Off -1 the Hook 's -1 -1 buildup -1 with remarkable assuredness -1 for a first-timer -1 -1 -1 -1 -1 -1 -1 . -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "Its scenes -1 and -1 sensibility -1 are all -1 more than -1 familiar -1 -1 -1 , -1 but -1 it exudes a kind -1 of nostalgic OOV charm -1 -1 -1 -1 -1 and -1 , at the same time -1 -1 -1 , -1 -1 -1 is so fresh -1 -1 and -1 free of the usual thriller nonsense -1 -1 -1 -1 -1 -1 that it all seems to be happening for the first time -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 \tground truth label: 3\n",
      "\n",
      "Bullock does a good job -1 -1 -1 here of working against her natural likability -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some correct predictions\n",
    "\n",
    "print 'Some correct binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(right_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A positive example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie 's -1 -1 ripe , enrapturing -1 -1 beauty -1 -1 will tempt those willing to probe its inscrutable mysteries -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "Attecntion vector of root:\n",
      "[ 0.00349537  0.00455809  0.01480896  0.02800366  0.0266175   0.04388244\n",
      "  0.00434648  0.03815329  0.03542445  0.03398605  0.05433063  0.03201456\n",
      "  0.03265094  0.00553974  0.0567746   0.01294396  0.07164057  0.0019329\n",
      "  0.05077274  0.00636492  0.04187195  0.04173682  0.03137547  0.03093641\n",
      "  0.03170796  0.03056097  0.03258435  0.03174249  0.03735219  0.03769103\n",
      "  0.01368807  0.04571361  0.        ]\n",
      "\n",
      "Indices of top 5 important nodes:\n",
      "[16 14 10 18 31]\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "willing\n",
      "tempt\n",
      "beauty\n",
      "probe\n",
      "will tempt those willing to probe its inscrutable mysteries . \n"
     ]
    }
   ],
   "source": [
    "k = 12 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Attecntion vector of root:'\n",
    "print attn[i][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes:'\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "print top_ind\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantet perfectly captures the hotel lobbies -1 -1 , -1 two-lane highways -1 -1 , -1 and -1 roadside cafes -1 that permeate Vincent 's -1 days -1 -1 -1 -1 -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "Attecntion vector of root:\n",
      "[ 0.04554181  0.03951189  0.04932036  0.00022318  0.030342    0.04970415\n",
      "  0.04887385  0.05224044  0.00124436  0.03921333  0.06084915  0.03297601\n",
      "  0.01959155  0.02685734  0.00124436  0.03535077  0.00094744  0.04310905\n",
      "  0.04978576  0.04826697  0.03682045  0.00094778  0.06222716  0.02522867\n",
      "  0.00435613  0.0031312   0.00289662  0.00170586  0.0130778   0.01822985\n",
      "  0.021375    0.0274193   0.03534235  0.03720098  0.        ]\n",
      "\n",
      "Indices of top 5 important nodes:\n",
      "[22 10  7 18  5]\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "permeate\n",
      "two-lane\n",
      "the hotel lobbies \n",
      "roadside\n",
      "lobbies\n"
     ]
    }
   ],
   "source": [
    "k = 24 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Attecntion vector of root:'\n",
    "print attn[i][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes:'\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "print top_ind\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At heart -1 the movie -1 is a deftly wrought suspense yarn -1 -1 -1 -1 whose richer shadings -1 work as coloring rather than substance -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 -1 \tground truth label: 4\n",
      "\n",
      "Attecntion vector of root:\n",
      "[ 0.00176917  0.04901871  0.03447079  0.0001959   0.00156532  0.00172315\n",
      "  0.00304355  0.00046547  0.0300404   0.03139539  0.02612001  0.03626014\n",
      "  0.03010962  0.03146257  0.03048464  0.03013186  0.00458601  0.05435914\n",
      "  0.03976879  0.02969466  0.00242321  0.00085276  0.0315246   0.0067939\n",
      "  0.0005196   0.03945554  0.0386363   0.05209846  0.05335733  0.04505504\n",
      "  0.0467037   0.03267373  0.0307165   0.02844965  0.03035104  0.00386342\n",
      "  0.02958277  0.02965588  0.        ]\n",
      "\n",
      "Indices of top 5 important nodes:\n",
      "[17 28 27  1 30]\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "richer\n",
      "coloring rather than substance \n",
      "rather than substance \n",
      "heart\n",
      "work as coloring rather than substance \n"
     ]
    }
   ],
   "source": [
    "k = 48 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Attecntion vector of root:'\n",
    "print attn[i][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes:'\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "print top_ind\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some incorrect binary predictions:\n",
      "\n",
      "If there 's a way to effectively teach kids about the dangers -1 of drugs -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 , I think it 's in projects like the -LRB- unfortunately R-rated -RRB- -1 -1 -1 -1 Paid -1 -1 -1 -1 -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "No. . -1 \tground truth label: 1\n",
      "\n",
      "The title Trapped -1 -1 turns out -1 to be a pretty fair -1 description -1 -1 of how you feel while you 're watching this OOV thriller -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 1\n",
      "\n",
      "Happily for Mr. Chin -1 -1 -1 -- though unhappily for his subjects -1 -1 -1 -1 -- -1 -1 the invisible hand -1 -1 of the marketplace -1 -1 -1 wrote a script -1 -1 that no human screenwriter -1 -1 could have hoped to match -1 -1 -1 -1 -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "Somewhere short -1 of Tremors on the modern OOV -1 -1 : -1 neither as funny -1 -1 nor -1 as clever -1 -1 -1 -1 -1 -1 , -1 though -1 -1 an agreeably -1 unpretentious way -1 to spend ninety minutes -1 -1 -1 -1 . -1 -1 -1 \tground truth label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some incorrect predictions\n",
    "\n",
    "print 'Some incorrect binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(wrong_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + ATTN 2\n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 200, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 5 x CELL + 2 X ATTN x CELL + ATTN = 741,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[ 97  66  10   2   2]\n",
      " [160 439 170  58  13]\n",
      " [  9  59  88  49   8]\n",
      " [ 12  66 114 320 186]\n",
      " [  1   3   7  81 190]]\n",
      "Overall Metrics:\n",
      " [[  892   786   193    25     8]\n",
      " [  969  6722  3932   575    73]\n",
      " [   87  1236 48295  1622    79]\n",
      " [   55   497  3930  7743  1399]\n",
      " [    5    14   198  1033  2232]]\n",
      "Root Binary Metrics:\n",
      " [[806  95]\n",
      " [106 814]]\n",
      "Overall Binary Metrics:\n",
      " [[10253  1157]\n",
      " [ 1010 13632]]\n",
      "mean loss: 18.475058, root_acc: 0.513122, overall_acc: 0.797627, root_binary_acc: 0.889621, overall_binary_acc: 0.916820\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/lstm_attn_cell200_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 200,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = LSTMAttnModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn = test(test_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + ATTN 3\n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 300, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 5 x CELL + 2 X ATTN x CELL + ATTN = 1,411,600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[101  69  11   0   1]\n",
      " [151 409 148  50   7]\n",
      " [ 13  70  88  32   6]\n",
      " [ 13  83 138 377 230]\n",
      " [  1   2   4  51 155]]\n",
      "Overall Metrics:\n",
      " [[  900   751   154     8     3]\n",
      " [  928  6444  3327   449    46]\n",
      " [   96  1385 48177  1472    57]\n",
      " [   80   666  4788  8421  1791]\n",
      " [    4     9   102   648  1894]]\n",
      "Root Binary Metrics:\n",
      " [[770  74]\n",
      " [142 835]]\n",
      "Overall Binary Metrics:\n",
      " [[10016   878]\n",
      " [ 1247 13911]]\n",
      "mean loss: 18.070416, root_acc: 0.511312, overall_acc: 0.797046, root_binary_acc: 0.881384, overall_binary_acc: 0.918432\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/lstm_attn_cell300_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 300,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = LSTMAttnModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn = test(test_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + ATTN + Layer2\n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 200, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 19 x CELL x CELL + 10 x CELL + 4 x ATTN x CELL + 2 x ATTN = 1,542,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[ 76  45   5   0   0]\n",
      " [178 464 180  66  11]\n",
      " [  6  54  64  31   5]\n",
      " [ 19  70 139 380 280]\n",
      " [  0   0   1  33 103]]\n",
      "Overall Metrics:\n",
      " [[  761   502    72     0     0]\n",
      " [ 1120  7044  3896   592    73]\n",
      " [   70  1180 49383  1656    69]\n",
      " [   56   528  3179  8367  2064]\n",
      " [    1     1    18   383  1585]]\n",
      "Root Binary Metrics:\n",
      " [[807  94]\n",
      " [105 815]]\n",
      "Overall Binary Metrics:\n",
      " [[10325  1099]\n",
      " [  938 13690]]\n",
      "mean loss: 16.465627, root_acc: 0.491855, overall_acc: 0.812833, root_binary_acc: 0.890719, overall_binary_acc: 0.921810\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/lstm_attn2_cell200_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 200,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'drop_fw_hs': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = LSTMAttn2Model(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn1, attn2 = test(test_md, layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + ATTN + Layer2\n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 300, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 19 x CELL x CELL + 10 x CELL + 4 x ATTN x CELL + 2 x ATTN = 3,183,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[138 110  24   1   2]\n",
      " [116 378 152  56   9]\n",
      " [ 17 101 105  68  17]\n",
      " [  8  41  99 268 122]\n",
      " [  0   3   9 117 249]]\n",
      "Overall Metrics:\n",
      " [[ 1107  1153   231    21    11]\n",
      " [  728  5965  2826   451    52]\n",
      " [  135  1798 50803  2105   123]\n",
      " [   31   319  2539  7004  1059]\n",
      " [    7    20   149  1417  2546]]\n",
      "Root Binary Metrics:\n",
      " [[822 103]\n",
      " [ 90 806]]\n",
      "Overall Binary Metrics:\n",
      " [[10214  1004]\n",
      " [ 1049 13785]]\n",
      "mean loss: 16.649294, root_acc: 0.514932, overall_acc: 0.816283, root_binary_acc: 0.894014, overall_binary_acc: 0.921196\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/lstm_attn2_cell300_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 300,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'drop_fw_hs': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = LSTMAttn2Model(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn1, attn2 = test(test_md, layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN + ATTN \n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 400, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x CELL + 2 x CELL x CELL + CELL + CELL x ATTN + ATTN =\n",
    "\n",
    "800,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[ 91  70  20   4   2]\n",
      " [157 389 157  81  20]\n",
      " [ 15  62  69  34  12]\n",
      " [ 16 111 139 351 263]\n",
      " [  0   1   4  40 102]]\n",
      "Overall Metrics:\n",
      " [[  617   530  1434    54    66]\n",
      " [ 1135  6427  6343  1164   137]\n",
      " [   88  1148 41865  1124    88]\n",
      " [  131  1047  5669  8046  2116]\n",
      " [   37   103  1237   610  1384]]\n",
      "Root Binary Metrics:\n",
      " [[766 129]\n",
      " [146 780]]\n",
      "Overall Binary Metrics:\n",
      " [[ 9451  1885]\n",
      " [ 1812 12904]]\n",
      "mean loss: 27.970765, root_acc: 0.453394, overall_acc: 0.706283, root_binary_acc: 0.848984, overall_binary_acc: 0.858092\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/rnn_attn_cell400_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 400,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = RNNAttnModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn = test(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some correct binary predictions:\n",
      "\n",
      "I loved it -1 ! -1 -1 \tground truth label: 4\n",
      "\n",
      "McKay deflates his piece -1 of puffery with a sour cliche -1 -1 -1 -1 and -1 heavy doses -1 of mean-spiritedness -1 -1 -1 -1 -1 -1 -1 \tground truth label: 1\n",
      "\n",
      "This is a throwaway , junk-food movie -1 -1 -1 -1 whose rap -1 soundtrack -1 was better -1 tended to than the film -1 -1 itself -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 0\n",
      "\n",
      "Smith 's -1 approach -1 is never -1 to tease -1 -1 , -1 except gently -1 and -1 in that way -1 that makes us consider our own eccentricities -1 -1 -1 -1 and -1 how they are expressed through our homes -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "Maybe I found the proceedings -1 a little bit -1 -1 too conventional -1 -1 -1 -1 . -1 -1 -1 \tground truth label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some correct predictions\n",
    "\n",
    "print 'Some correct binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(right_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie 's -1 -1 ripe , enrapturing -1 -1 beauty -1 -1 will tempt those willing to probe its inscrutable mysteries -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "Attecntion vector of root:\n",
      "[ 0.00472508  0.01236391  0.00592726  0.00581668  0.00370169  0.02663458\n",
      "  0.00336349  0.11336799  0.0454242   0.04113133  0.07280442  0.0481532\n",
      "  0.04172279  0.00927238  0.08192968  0.00308198  0.02412561  0.00369212\n",
      "  0.00277828  0.00409471  0.13038668  0.02992338  0.00652305  0.00495997\n",
      "  0.00332622  0.00362642  0.00552763  0.00367674  0.0142454   0.01965987\n",
      "  0.058197    0.05986447  0.        ]\n",
      "\n",
      "Indices of top 5 important nodes:\n",
      "[20  7 14 10 31]\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "inscrutable\n",
      "enrapturing\n",
      "tempt\n",
      "beauty\n",
      "will tempt those willing to probe its inscrutable mysteries         . \n"
     ]
    }
   ],
   "source": [
    "k = 12 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Attecntion vector of root:'\n",
    "print attn[i][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes:'\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "print top_ind\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story -1 loses its bite -1 -1 in a last-minute happy ending -1 -1 -1 that 's even less plausible -1 -1 than the rest -1 of the picture -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 0\n",
      "\n",
      "Attecntion vector of root:\n",
      "[ 0.00454059  0.00915212  0.0042886   0.05790763  0.00304922  0.04729232\n",
      "  0.00421499  0.00873589  0.00848241  0.00367327  0.06181822  0.05534934\n",
      "  0.00308452  0.04477623  0.08128538  0.05717977  0.00304677  0.00617294\n",
      "  0.00956263  0.03983257  0.03761867  0.01154378  0.0208891   0.01960257\n",
      "  0.00449949  0.03010256  0.00673123  0.00268357  0.00449949  0.01133271\n",
      "  0.01172593  0.0047576   0.00579599  0.0067781   0.00949739  0.0129954\n",
      "  0.00828245  0.03789391  0.00960336  0.01505514  0.05788542  0.09494645\n",
      "  0.        ]\n",
      "\n",
      "Indices of top 5 important nodes:\n",
      "[41 14 10  3 40]\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "loses its bite   in a last-minute happy ending    that 's even less plausible   than the rest  of the picture           . \n",
      "last-minute happy ending  \n",
      "last-minute\n",
      "loses\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "k = 24 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Attecntion vector of root:'\n",
    "print attn[i][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes:'\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "print top_ind\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gollum 's -1 ` performance ' -1 -1 -1 is incredible -1 ! -1 -1 \tground truth label: 4\n",
      "\n",
      "Attecntion vector of root:\n",
      "[ 0.12941813  0.01561992  0.00880938  0.025031    0.0617275   0.02064649\n",
      "  0.04642288  0.03932489  0.00750063  0.02774767  0.06765139  0.08335026\n",
      "  0.16085345  0.11467416  0.        ]\n",
      "\n",
      "Indices of top 5 important nodes:\n",
      "[12  0 13 11 10]\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "!\n",
      "Gollum\n",
      "is incredible  ! \n",
      "is incredible \n",
      "incredible\n"
     ]
    }
   ],
   "source": [
    "k = 48 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Attecntion vector of root:'\n",
    "print attn[i][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes:'\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "print top_ind\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some incorrect binary predictions:\n",
      "\n",
      "Watching Beanie -1 and -1 his gang -1 -1 put together -1 his slasher video -1 -1 -1 from spare parts -1 -1 -1 and -1 borrowed materials is as much fun -1 -1 -1 as it must have been for them to make it -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "What Full Frontal -1 lacks in thematic coherence -1 -1 -1 -1 -1 it largely makes up -1 for as loosey-goosey , experimental entertainment -1 -1 -1 -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "The two leads -1 -1 are almost -1 good enough -1 to camouflage the dopey plot -1 -1 -1 -1 -1 -1 -1 , -1 but -1 so much naturalistic small talk -1 -1 -1 -1 , -1 delivered in almost muffled -1 exchanges -1 -1 -1 -1 , -1 eventually has a lulling effect -1 -1 -1 -1 -1 -1 . -1 \tground truth label: 1\n",
      "\n",
      "The tone -1 shifts abruptly -1 from tense -1 -1 to celebratory to soppy -1 -1 -1 -1 . -1 -1 \tground truth label: 1\n",
      "\n",
      "Blessed with immense physical prowess -1 -1 -1 -1 he may well -1 be -1 -1 -1 , -1 but -1 Ahola is simply -1 not an actor -1 -1 -1 -1 -1 . -1 \tground truth label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some incorrect predictions\n",
    "\n",
    "print 'Some incorrect binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(wrong_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN + ATTN + 2Layers\n",
    "\n",
    "Num of params:\n",
    "\n",
    "EMB = 300, CELL = 400, ATTN = 150\n",
    "\n",
    "(EMB + 2 x CELL) x CELL + 7 x CELL x CELL + 2 x CELL + CELL x ATTN x 4 + ATTN x 2 = 1,801,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[ 84  58  19   3   2]\n",
      " [168 430 174  91  26]\n",
      " [ 14  74  79  44  16]\n",
      " [ 13  62 112 320 226]\n",
      " [  0   9   5  52 129]]\n",
      "Overall Metrics:\n",
      " [[  685   664   699   217    57]\n",
      " [ 1111  6460  7864  1620   182]\n",
      " [  102  1315 41943  1663   152]\n",
      " [  103   772  5660  6812  1738]\n",
      " [    7    44   382   686  1662]]\n",
      "Root Binary Metrics:\n",
      " [[812 142]\n",
      " [100 767]]\n",
      "Overall Binary Metrics:\n",
      " [[ 9967  2965]\n",
      " [ 1296 11824]]\n",
      "mean loss: 28.911734, root_acc: 0.471493, overall_acc: 0.696877, root_binary_acc: 0.867106, overall_binary_acc: 0.836442\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/rnn_attn2_cell400_attn150/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 400,\n",
    "               'attn_size': 150,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'drop_fw_hs': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = RNNAttn2Model(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn1, attn2 = test(test_md, layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some correct binary predictions:\n",
      "\n",
      "Obvious politics -1 and -1 rudimentary animation -1 -1 reduce the chances -1 that the appeal -1 of Hey Arnold -1 -1 -1 -1 -1 -1 ! -1 -1 \tground truth label: 1\n",
      "\n",
      "Just when the movie -1 seems confident enough -1 to handle subtlety -1 -1 -1 -1 -1 -1 -1 , it dives into soapy bathos -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 1\n",
      "\n",
      "It 's neither as romantic -1 nor -1 as thrilling -1 as it should be -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 0\n",
      "\n",
      "Succeeds in providing a disquiet world -1 -1 -1 the OOV completion -1 -1 of the Police Academy series -1 -1 -1 -1 -1 -1 -1 -1 . -1 \tground truth label: 3\n",
      "\n",
      "OOV ridiculous -1 , OOV noisy -1 . -1 -1 -1 \tground truth label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some correct predictions\n",
    "\n",
    "print 'Some correct binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(right_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A thoughtful , provocative , insistently humanizing -1 -1 -1 -1 -1 film -1 -1 . -1 \tground truth label: 4\n",
      "\n",
      "Indices of top 5 important nodes (from layer 1):\n",
      "[13 11  9  0  1]\n",
      "Indices of top 5 important nodes (from layer 2):\n",
      "[13  5  1  9  3]\n",
      "\n",
      "Top 5 important sub-strings (from layer 1):\n",
      "thoughtful , provocative , insistently humanizing film \n",
      "thoughtful , provocative , insistently humanizing \n",
      "provocative , insistently humanizing \n",
      "A\n",
      "thoughtful\n",
      "Top 5 important sub-strings (from layer 2):\n",
      "thoughtful , provocative , insistently humanizing film \n",
      "insistently\n",
      "thoughtful\n",
      "provocative , insistently humanizing \n",
      "provocative\n"
     ]
    }
   ],
   "source": [
    "k = 12 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes (from layer 1):'\n",
    "top_ind1 = np.argsort(attn1[i][-1])[::-1][:5]\n",
    "print top_ind1\n",
    "print 'Indices of top 5 important nodes (from layer 2):'\n",
    "top_ind2 = np.argsort(attn2[i][-1])[::-1][:5]\n",
    "print top_ind2\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings (from layer 1):'\n",
    "for ind in top_ind1:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])\n",
    "print 'Top 5 important sub-strings (from layer 2):'\n",
    "for ind in top_ind2:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantet perfectly captures the hotel lobbies -1 -1 , -1 two-lane highways -1 -1 , -1 and -1 roadside cafes -1 that permeate Vincent 's -1 days -1 -1 -1 -1 -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "Indices of top 5 important nodes (from layer 1):\n",
      "[32 17 28 27 31]\n",
      "Indices of top 5 important nodes (from layer 2):\n",
      "[ 1 18 33 10 11]\n",
      "\n",
      "Top 5 important sub-strings (from layer 1):\n",
      "captures the hotel lobbies , two-lane highways , and roadside cafes that permeate Vincent 's days \n",
      "the hotel lobbies , two-lane highways , and \n",
      "permeate Vincent 's days \n",
      "Vincent 's days \n",
      "the hotel lobbies , two-lane highways , and roadside cafes that permeate Vincent 's days \n",
      "Top 5 important sub-strings (from layer 2):\n",
      "perfectly\n",
      "roadside\n",
      "perfectly captures the hotel lobbies , two-lane highways , and roadside cafes that permeate Vincent 's days \n",
      "two-lane\n",
      "highways\n"
     ]
    }
   ],
   "source": [
    "k = 24 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes (from layer 1):'\n",
    "top_ind1 = np.argsort(attn1[i][-1])[::-1][:5]\n",
    "print top_ind1\n",
    "print 'Indices of top 5 important nodes (from layer 2):'\n",
    "top_ind2 = np.argsort(attn2[i][-1])[::-1][:5]\n",
    "print top_ind2\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings (from layer 1):'\n",
    "for ind in top_ind1:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])\n",
    "print 'Top 5 important sub-strings (from layer 2):'\n",
    "for ind in top_ind2:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's traditional -1 moviemaking all the way -1 -1 -1 -1 -1 , -1 but -1 it 's done with a lot -1 of careful period attention -1 -1 as well as -1 -1 -1 some very welcome wit -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 \tground truth label: 4\n",
      "\n",
      "Indices of top 5 important nodes (from layer 1):\n",
      "[16 50 38 46  3]\n",
      "Indices of top 5 important nodes (from layer 2):\n",
      "[14 11 29 43 25]\n",
      "\n",
      "Top 5 important sub-strings (from layer 1):\n",
      "It 's traditional moviemaking all the way , but \n",
      "It 's traditional moviemaking all the way , but it 's done with a lot of careful period attention as well as some very welcome wit \n",
      "welcome\n",
      "with a lot of careful period attention as well as some very welcome wit \n",
      "'s traditional \n",
      "Top 5 important sub-strings (from layer 2):\n",
      "It 's traditional moviemaking all the way , \n",
      "'s traditional moviemaking all the way \n",
      "careful period attention \n",
      "careful period attention as well as some very welcome wit \n",
      "careful\n"
     ]
    }
   ],
   "source": [
    "k = 128 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "print 'Indices of top 5 important nodes (from layer 1):'\n",
    "top_ind1 = np.argsort(attn1[i][-1])[::-1][:5]\n",
    "print top_ind1\n",
    "print 'Indices of top 5 important nodes (from layer 2):'\n",
    "top_ind2 = np.argsort(attn2[i][-1])[::-1][:5]\n",
    "print top_ind2\n",
    "print\n",
    "\n",
    "print 'Top 5 important sub-strings (from layer 1):'\n",
    "for ind in top_ind1:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])\n",
    "print 'Top 5 important sub-strings (from layer 2):'\n",
    "for ind in top_ind2:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some incorrect binary predictions:\n",
      "\n",
      "The story -1 is familiar from its many predecessors -1 -1 -1 -1 -1 -1 ; -1 like them -1 , it eventually culminates in the OOV -1 - -1 stunning insight -1 that crime does n't -1 pay -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 \tground truth label: 1\n",
      "\n",
      "It is far from the worst -1 , -1 thanks to the topical issues -1 -1 it raises , -1 the performances -1 of Stewart and -1 Hardy -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 , and -1 that essential feature -1 -- -1 a decent full-on space battle -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "It 's a great deal -1 -1 of sizzle and -1 very little -1 -1 steak -1 -1 -1 -1 . -1 -1 \tground truth label: 1\n",
      "\n",
      "The story -1 is familiar from its many predecessors -1 -1 -1 -1 -1 -1 ; -1 like them -1 , it eventually culminates in the OOV -1 - -1 stunning insight -1 that crime does n't -1 pay -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 \tground truth label: 1\n",
      "\n",
      "Based on a David Leavitt story -1 -1 -1 -1 -1 , the film -1 shares that writer 's -1 -1 usual blend -1 -1 of observant cleverness -1 , -1 OOV coincidence -1 -1 and -1 slightly noxious -1 preciousness -1 -1 -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of some incorrect predictions\n",
    "\n",
    "print 'Some incorrect binary predictions:\\n'\n",
    "for _ in range(5):\n",
    "    ind = random.choice(wrong_ind)\n",
    "    print ind2str(test_data[ind][0]), '\\tground truth label:', test_data[ind][1][-1]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GRU v1+ ATTN \n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 150, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 5 x CELL + 2 x ATTN x CELL + ATTN = 480,850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[122  93  16   1   2]\n",
      " [136 407 160  77  18]\n",
      " [ 10  56  92  50  10]\n",
      " [ 10  65 111 285 146]\n",
      " [  1  12  10  97 223]]\n",
      "Overall Metrics:\n",
      " [[  970   918   237    26     9]\n",
      " [  894  6684  4366   691    85]\n",
      " [   89  1201 48175  1662    98]\n",
      " [   43   409  3615  7713  1432]\n",
      " [   12    43   155   906  2167]]\n",
      "Root Binary Metrics:\n",
      " [[811 129]\n",
      " [101 780]]\n",
      "Overall Binary Metrics:\n",
      " [[10359  1377]\n",
      " [  904 13412]]\n",
      "mean loss: 18.100765, root_acc: 0.510860, overall_acc: 0.795508, root_binary_acc: 0.873696, overall_binary_acc: 0.912444\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/gru_attn_cell150_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 150,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = GRUAttnModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn = test(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offers a breath -1 of the fresh air -1 -1 of true sophistication -1 -1 -1 -1 -1 -1 . -1 \tground truth label: 4\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "breath\n",
      "sophistication\n",
      "Offers a breath of the fresh air of true sophistication \n",
      "a breath of the fresh air of true sophistication \n",
      "Offers\n"
     ]
    }
   ],
   "source": [
    "k = 12 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Though it is by no means -1 his best work -1 -1 -1 -1 -1 -1 -1 , OOV is a distinguished and -1 distinctive -1 effort -1 -1 by a bona-fide master -1 -1 , -1 a fascinating film -1 -1 replete with rewards to be had by all willing to make the effort to reap them -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "reap\n",
      "no means his best work \n",
      "it is by no means his best work \n",
      "is by no means his best work \n",
      "by no means his best work \n"
     ]
    }
   ],
   "source": [
    "k = 25 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A truly moving -1 experience -1 -1 , -1 and -1 a perfect example -1 -1 of how art -- when done right -1 -1 -- -1 -1 -1 can help heal -1 -1 -1 -1 -1 -1 -1 , -1 clarify , -1 and -1 comfort -1 . -1 -1 \tground truth label: 4\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "clarify\n",
      "when\n",
      "help\n",
      "heal\n",
      "perfect example \n"
     ]
    }
   ],
   "source": [
    "k = 48 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU v1+ ATTN \n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 400, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 5 x CELL + 2 x ATTN x CELL + ATTN = 2,282,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[115  91  19   2   0]\n",
      " [147 428 157  72  13]\n",
      " [  8  54  87  37  12]\n",
      " [  8  55 118 316 172]\n",
      " [  1   5   8  83 202]]\n",
      "Overall Metrics:\n",
      " [[  892   774   185    14     3]\n",
      " [  963  6558  3567   568    64]\n",
      " [  105  1498 48751  1751   100]\n",
      " [   43   410  3931  7947  1597]\n",
      " [    5    15   114   718  2027]]\n",
      "Root Binary Metrics:\n",
      " [[825 106]\n",
      " [ 87 803]]\n",
      "Overall Binary Metrics:\n",
      " [[10293  1142]\n",
      " [  970 13647]]\n",
      "mean loss: 17.765202, root_acc: 0.519457, overall_acc: 0.801150, root_binary_acc: 0.894014, overall_binary_acc: 0.918931\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/gru_attn_cell400_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 400,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = GRUAttnModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn = test(test_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU v1+ ATTN + Layer2\n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 200, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 10 x CELL + 15 x CELL x CELL + 4 x ATTN x CELL + 2 x ATTN = 1,400,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[163 186  37   9   3]\n",
      " [ 84 268 116  41   6]\n",
      " [ 23 127 127  84  23]\n",
      " [  5  39  89 215  91]\n",
      " [  4  13  20 161 276]]\n",
      "Overall Metrics:\n",
      " [[ 1326  2276  2088   274    30]\n",
      " [  494  5316  5009   621    40]\n",
      " [  119  1127 44671  1431   116]\n",
      " [   38   377  3207  5993   717]\n",
      " [   31   159  1573  2679  2888]]\n",
      "Root Binary Metrics:\n",
      " [[799 101]\n",
      " [113 808]]\n",
      "Overall Binary Metrics:\n",
      " [[10280  1679]\n",
      " [  983 13110]]\n",
      "mean loss: 26.253259, root_acc: 0.474661, overall_acc: 0.728741, root_binary_acc: 0.882482, overall_binary_acc: 0.897820\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/gru_attn2_cell200_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 200,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'drop_fw_hs': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = GRUAttn2Model(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn1, attn2 = test(test_md, layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU v1+ ATTN + Layer2\n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 300, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 10 x CELL + 15 x CELL x CELL + 4 x ATTN x CELL + 2 x ATTN = 2,823,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[108  83  24   7   3]\n",
      " [152 450 197 104  19]\n",
      " [  5  23  39  17   5]\n",
      " [ 13  73 121 328 224]\n",
      " [  1   4   8  54 148]]\n",
      "Overall Metrics:\n",
      " [[ 1040  1302  1054   219    64]\n",
      " [  840  6611  6313  1276   137]\n",
      " [   41   592 43713  1057    59]\n",
      " [   68   626  4498  7505  1719]\n",
      " [   19   124   970   941  1812]]\n",
      "Root Binary Metrics:\n",
      " [[806 140]\n",
      " [106 769]]\n",
      "Overall Binary Metrics:\n",
      " [[10133  2254]\n",
      " [ 1130 12535]]\n",
      "mean loss: 26.040727, root_acc: 0.485520, overall_acc: 0.734637, root_binary_acc: 0.864909, overall_binary_acc: 0.870106\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/gru_attn2_cell300_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 300,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'drop_fw_hs': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = GRUAttn2Model(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn1, attn2 = test(test_md, layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU v1+ ATTN + Layer2\n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 400, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 5 x CELL + 10 x CELL + 15 x CELL x CELL + 4 x ATTN x CELL + 2 x ATTN = 4,764,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[ 84  61  10   0   1]\n",
      " [181 474 192 106  22]\n",
      " [ 10  65  96  71  26]\n",
      " [  4  33  89 297 225]\n",
      " [  0   0   2  36 125]]\n",
      "Overall Metrics:\n",
      " [[  764   654   724   119    33]\n",
      " [ 1111  7132  5213   933   119]\n",
      " [   88  1088 46324  1510   139]\n",
      " [   44   357  3684  7778  1904]\n",
      " [    1    24   603   658  1596]]\n",
      "Root Binary Metrics:\n",
      " [[854 187]\n",
      " [ 58 722]]\n",
      "Overall Binary Metrics:\n",
      " [[10616  2178]\n",
      " [  647 12611]]\n",
      "mean loss: 22.463824, root_acc: 0.486878, overall_acc: 0.769903, root_binary_acc: 0.865459, overall_binary_acc: 0.891563\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/gru_attn2_cell400_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 400,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'drop_fw_hs': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = GRUAttn2Model(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn1, attn2 = test(test_md, layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU v2 + ATTN \n",
    "\n",
    "Num of params: \n",
    "\n",
    "EMB = 300, CELL = 400, ATTN = 100\n",
    "\n",
    "(EMB + 2 x CELL) x 4 x CELL + 4 x CELL + 2 x ATTN x CELL + ATTN = 1,841,700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "test finish\n",
      "Root Metrics:\n",
      " [[151 127  28   7   3]\n",
      " [ 95 357 128  55   9]\n",
      " [ 19  76  95  49  13]\n",
      " [ 12  65 128 335 205]\n",
      " [  2   8  10  64 169]]\n",
      "Overall Metrics:\n",
      " [[ 1100  1354  1461   131    30]\n",
      " [  716  6017  4284   542    48]\n",
      " [  100  1280 44969  1438   104]\n",
      " [   74   542  4541  8009  1669]\n",
      " [   18    62  1293   878  1940]]\n",
      "Root Binary Metrics:\n",
      " [[797  94]\n",
      " [115 815]]\n",
      "Overall Binary Metrics:\n",
      " [[10064  1341]\n",
      " [ 1199 13448]]\n",
      "mean loss: 23.230562, root_acc: 0.500905, overall_acc: 0.751029, root_binary_acc: 0.885228, overall_binary_acc: 0.902503\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'model/gru2_attn_cell400_attn100/'\n",
    "config_dict = {'embed_size': 300,\n",
    "               'fw_cell_size': 400,\n",
    "               'attn_size': 100,\n",
    "               'wv_emb_file': 'tmp/embeddings.pkl',\n",
    "               'wv_dict': '_data/dict.pkl',\n",
    "               'wv_vocab_size': 20726,\n",
    "               'mask_type': 'subtree_mask',\n",
    "               'drop_embed': False,\n",
    "               'drop_weight': False,\n",
    "               'class_size': 5,\n",
    "               'rec_keep_prob': 0.0,\n",
    "               'output_keep_prob': 0.0,\n",
    "               'L2_lambda': 0.0\n",
    "               }\n",
    "\n",
    "test_md = GRU2AttnModel(config_dict)\n",
    "test_md.is_training = False\n",
    "test_md.add_variables(reuse=False)\n",
    "test_md.build_model(left, right, wv, label, is_leaf, l, mask)\n",
    "\n",
    "tf.train.Saver().restore(sess, model_dir)\n",
    "\n",
    "right_ind, wrong_ind, attn = test(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An utterly -1 compelling ` -1 who wrote it -1 ' -1 in which the reputation -1 of the most famous -1 author -1 -1 who ever lived -1 -1 -1 -1 -1 comes into question -1 -1 -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 3\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "compelling ` who wrote it ' in which the reputation of the most famous author who ever lived comes into question . \n",
      "compelling ` who wrote it ' in which the reputation of the most famous author who ever lived comes into question \n",
      "the most famous author who ever lived \n",
      "An utterly \n",
      "the reputation of the most famous author who ever lived comes into question \n"
     ]
    }
   ],
   "source": [
    "k = 10 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At about 95 -1 minutes -1 -1 , Treasure Planet -1 maintains a brisk pace -1 -1 as it races -1 -1 -1 -1 through the familiar story -1 -1 -1 -1 . -1 -1 -1 -1 \tground truth label: 3\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "maintains a brisk pace as it races through the familiar story . \n",
      "maintains a brisk pace as it races through the familiar story \n",
      "a brisk pace as it races \n",
      "Treasure Planet maintains a brisk pace as it races through the familiar story . \n",
      "brisk pace \n"
     ]
    }
   ],
   "source": [
    "k = 20 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuller would surely -1 have called this gutsy -1 and -1 at times exhilarating -1 movie -1 -1 -1 a great yarn -1 -1 -1 -1 -1 -1 . -1 -1 \tground truth label: 4\n",
      "\n",
      "Top 5 important sub-strings:\n",
      "would surely have called this gutsy and at times exhilarating movie a great yarn . \n",
      "would surely have called this gutsy and at times exhilarating movie a great yarn \n",
      "this gutsy and at times exhilarating movie \n",
      "Fuller\n",
      "this gutsy and at times exhilarating movie a great yarn \n"
     ]
    }
   ],
   "source": [
    "k = 30 # randomly select a correct predition for detailed analysis\n",
    "i = right_ind[k]\n",
    "print ind2str(test_data[i][0]), '\\tground truth label:', test_data[i][1][-1]\n",
    "print\n",
    "\n",
    "top_ind = np.argsort(attn[i][-1])[::-1][:5]\n",
    "\n",
    "print 'Top 5 important sub-strings:'\n",
    "for ind in top_ind:\n",
    "    print nodeid2str(ind, test_data[i][0], test_data[i][2], test_data[i][3], test_data[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
